# AIFFEL Campus Online Code Peer Review Templete
- 코더 : 이호창
- 리뷰어 : 김민혁


# PRT(Peer Review Template)
- [X]  **1. 주어진 문제를 해결하는 완성된 코드가 제출되었나요?**
    - 문제에서 요구하는 최종 결과물이 첨부되었는지 확인
        - 중요! 해당 조건을 만족하는 부분을 캡쳐해 근거로 첨부
     
  ![image](https://github.com/user-attachments/assets/7ecb0fb7-f990-40f1-86a4-f155bd3d20b9)

    | 한국어로 입력을 받으면 잘 답변 출력이 나오는 것을 확인했다. 영어 전처리도 진행해줘봤지만, 영어는 답변을 잘 못한다는 결론을 내리셔서 좋았다.

    
- [X]  **2. 전체 코드에서 가장 핵심적이거나 가장 복잡하고 이해하기 어려운 부분에 작성된 
주석 또는 doc string을 보고 해당 코드가 잘 이해되었나요?**
    - 해당 코드 블럭을 왜 핵심적이라고 생각하는지 확인
    - 해당 코드 블럭에 doc string/annotation이 달려 있는지 확인
    - 해당 코드의 기능, 존재 이유, 작동 원리 등을 기술했는지 확인
    - 주석을 보고 코드 이해가 잘 되었는지 확인
        - 중요! 잘 작성되었다고 생각되는 부분을 캡쳐해 근거로 첨부
     
  ![image](https://github.com/user-attachments/assets/d23990a6-2c40-40e0-8ad8-451c3233f744)

    | 샘플의 정소 인코딩 작업과 샘플의 최대 길이. 즉 토큰 입력 개수에 대해 성능이 많이 바뀌는 것 같다. 길이가 길어질 수록 패딩으로 채워지니 성능에 영향을 많이주는 것 같다.

        
- [X]  **3. 에러가 난 부분을 디버깅하여 문제를 해결한 기록을 남겼거나
새로운 시도 또는 추가 실험을 수행해봤나요?**
    - 문제 원인 및 해결 과정을 잘 기록하였는지 확인
    - 프로젝트 평가 기준에 더해 추가적으로 수행한 나만의 시도, 
    실험이 기록되어 있는지 확인
        - 중요! 잘 작성되었다고 생각되는 부분을 캡쳐해 근거로 첨부
     
  ![image](https://github.com/user-attachments/assets/c264571a-20b9-4478-b0ae-3ac69c904edc)

    | 모델을 컴파일하고 훈련 하기 전에 에포크 설정에 따른 조기종료(Early Stopping)를 시도해보려 했지만. 이 데이터와 모델에선 validation 데이터를 만들어내지 못해 새로운 시도를 도전해봤다는 그 점이 굉장히 좋았다.

        
- [X]  **4. 회고를 잘 작성했나요?**
    - 주어진 문제를 해결하는 완성된 코드 내지 프로젝트 결과물에 대해
    배운점과 아쉬운점, 느낀점 등이 기록되어 있는지 확인
    - 전체 코드 실행 플로우를 그래프로 그려서 이해를 돕고 있는지 확인
        - 중요! 잘 작성되었다고 생각되는 부분을 캡쳐해 근거로 첨부
     
  ![image](https://github.com/user-attachments/assets/ad1843ac-df1b-4d01-91d2-935b4d669c6b)

    | max_length를 다시 설정하고 이어 학습하겠다는 의지와 모델의 성능이 잘 안나온다면, 작은 것까지 디버깅해보는 중요성을 느꼈다.
        
- [X]  **5. 코드가 간결하고 효율적인가요?**
    - 파이썬 스타일 가이드 (PEP8) 를 준수하였는지 확인
    - 코드 중복을 최소화하고 범용적으로 사용할 수 있도록 함수화/모듈화했는지 확인
        - 중요! 잘 작성되었다고 생각되는 부분을 캡쳐해 근거로 첨부
     
  ![image](https://github.com/user-attachments/assets/e060d5ea-e165-4a6a-93cc-ace3471a88b2)

    | 교사 강요 부분을 잘 몰랐었는데, 주석으로 친절하게 설명하셨고, 이 dataset 함수를 통해 훈련 속도를 향상시키게 하는 원리를 알았다.



# 회고(참고 링크 및 코드 개선)
```
accuracy는 마의 17%를 뚫었지만, 손실 값이 1.0대로 나와서 조금 아쉬웠다. 하지만, 영어와 한글을 고려한 전처리, max_length 길이, 에폭의 수를 더 조정하신다면 충분히 더 좋은 성능과 평가가 나올 것 같다. 이를 통해 영어 입력은 잘 반영되지 않는 것 처럼, 다양한 도전은 새로운 방향성을 충분히 더 찾을 수 있을 것 같드시다. 이러한 무한한 가능성과 성장에 칭찬을 드립니다:)                                                          
```

