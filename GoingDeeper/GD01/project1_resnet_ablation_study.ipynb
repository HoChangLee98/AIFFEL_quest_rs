{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c8f884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "# Tensorflow가 활용할 GPU가 장착되어 있는지 확인해 봅니다.\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc9dddf",
   "metadata": {},
   "source": [
    "### 1) ResNet 기본 블록 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4af5af87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet34_block(\n",
    "    input_layer,\n",
    "    num_cnn=3, \n",
    "    channel=64,\n",
    "    block_num=1,\n",
    "    is_plain=False\n",
    "):\n",
    "    # 입력 레이어\n",
    "    x = input_layer\n",
    "\n",
    "    ## CNN 레이어\n",
    "    for cnn_num in range(num_cnn):\n",
    "        identity = x\n",
    "        x = keras.layers.Conv2D(\n",
    "            filters=channel,\n",
    "            kernel_size=(3,3),\n",
    "            kernel_initializer='he_normal',\n",
    "            padding='same',\n",
    "            name=f'block{block_num}_1_conv{cnn_num}'\n",
    "        )(x)\n",
    "        x = keras.layers.BatchNormalization(\n",
    "            name=f'block{block_num}_1_batch_normal{cnn_num}'\n",
    "        )(x)\n",
    "        x = keras.layers.Activation(\n",
    "            \"relu\", \n",
    "            name=f'block{block_num}_1_activation{cnn_num}'\n",
    "        )(x)\n",
    "        \n",
    "        x = keras.layers.Conv2D(\n",
    "            filters=channel,\n",
    "            kernel_size=(3,3),\n",
    "            kernel_initializer='he_normal',\n",
    "            padding='same',\n",
    "            name=f'block{block_num}_2_conv{cnn_num}'\n",
    "        )(x)\n",
    "        x = keras.layers.BatchNormalization(\n",
    "            name=f'block{block_num}_2_batch_normal{cnn_num}'\n",
    "        )(x)\n",
    "        \n",
    "        if not is_plain:\n",
    "            ## skip connection의 채널 수를 맞춰준다. \n",
    "            if identity.shape[-1] != x.shape[-1]:\n",
    "                identity = keras.layers.Conv2D(\n",
    "                    filters=x.shape[-1], \n",
    "                    kernel_size=(1, 1), \n",
    "                    strides=(1, 1), \n",
    "                    padding='same'\n",
    "                )(identity)\n",
    "\n",
    "            x = keras.layers.Add()([x,identity])\n",
    "        \n",
    "        x = keras.layers.Activation(\n",
    "            \"relu\", \n",
    "            name=f'block{block_num}_2_activation{cnn_num}'\n",
    "        )(x)        \n",
    "        \n",
    "    #     Max Pooling 레이어\n",
    "    # 마지막 블록 뒤에는 pooling을 하지 않음\n",
    "    if cnn_num != (num_cnn-1):        \n",
    "        x = keras.layers.MaxPooling2D(\n",
    "            pool_size=(2, 2),\n",
    "            strides=2,\n",
    "            name=f'block{block_num}_pooling'\n",
    "        )(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bb2e6a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet50_block(\n",
    "    input_layer,\n",
    "    num_cnn=3, \n",
    "    channel=64,\n",
    "    block_num=1,\n",
    "    is_plain=False\n",
    "):\n",
    "    # 입력 레이어\n",
    "    x = input_layer\n",
    "\n",
    "    ## CNN 레이어\n",
    "    for cnn_num in range(num_cnn):\n",
    "        identity = x\n",
    "        x = keras.layers.Conv2D(\n",
    "            filters=channel,\n",
    "            kernel_size=(1,1),\n",
    "            kernel_initializer='he_normal',\n",
    "#             padding='same',\n",
    "            name=f'block{block_num}_1_conv{cnn_num}'\n",
    "        )(x)\n",
    "        x = keras.layers.BatchNormalization(\n",
    "            name=f'block{block_num}_1_batch_normal{cnn_num}'\n",
    "        )(x)\n",
    "        x = keras.layers.Activation(\n",
    "            \"relu\", \n",
    "            name=f'block{block_num}_1_activation{cnn_num}'\n",
    "        )(x)\n",
    "        \n",
    "        x = keras.layers.Conv2D(\n",
    "            filters=channel,\n",
    "            kernel_size=(3,3),\n",
    "            kernel_initializer='he_normal',\n",
    "            padding='same',\n",
    "            name=f'block{block_num}_2_conv{cnn_num}'\n",
    "        )(x)\n",
    "        x = keras.layers.BatchNormalization(\n",
    "            name=f'block{block_num}_2_batch_normal{cnn_num}'\n",
    "        )(x)\n",
    "        x = keras.layers.Activation(\n",
    "            \"relu\", \n",
    "            name=f'block{block_num}_2_activation{cnn_num}'\n",
    "        )(x)\n",
    "        \n",
    "        if num_cnn == 0:\n",
    "            identity = keras.layers.Conv2D(\n",
    "                filters=channel*4,\n",
    "                kernel_size=(1,1),\n",
    "                kernel_initializer='he_normal',\n",
    "                padding='same',\n",
    "                name=f'block{block_num}_0_conv{cnn_num}'\n",
    "            )(identity)\n",
    "        \n",
    "        x = keras.layers.Conv2D(\n",
    "            filters=channel*4,\n",
    "            kernel_size=(1,1),\n",
    "            kernel_initializer='he_normal',\n",
    "            padding='same',\n",
    "            name=f'block{block_num}_3_conv{cnn_num}'\n",
    "        )(x)\n",
    "        x = keras.layers.BatchNormalization(\n",
    "            name=f'block{block_num}_3_batch_normal{cnn_num}'\n",
    "        )(x)\n",
    "\n",
    "        if not is_plain:\n",
    "            ## skip connection의 채널 수를 맞춰준다. \n",
    "            if identity.shape[-1] != x.shape[-1]:\n",
    "                identity = keras.layers.Conv2D(filters=x.shape[-1], kernel_size=(1, 1), strides=(1, 1), padding='same')(identity)\n",
    "\n",
    "            x = keras.layers.Add()([x,identity])\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        if cnn_num != (num_cnn - 1):        \n",
    "            x = keras.layers.MaxPooling2D(\n",
    "                pool_size=(2, 2),\n",
    "                strides=2,\n",
    "                name=f'block{block_num}_pooling{cnn_num}'\n",
    "            )(x)\n",
    "        \n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "10316b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet 모델 자체를 생성하는 함수입니다.\n",
    "def build_resnet(\n",
    "    input_shape=(224,224,3),\n",
    "    num_cnn_list=[3,4,6,3],  # ResNet-34 혹은 ResNet-50 구조에서 사용할 CNN 개수\n",
    "    channel_list=[64,128,256,512],   # 각 블록의 채널 크기\n",
    "    num_classes=2,   # 분류할 클래스 수\n",
    "    is_50=False,      # False면 ResNet-34, True면 ResNet-50\n",
    "    is_plain=False    # Plain 네트워크 여부 (skip connection을 사용하지 않는지 여부)\n",
    "):\n",
    "    \n",
    "    assert len(num_cnn_list) == len(channel_list) #모델을 만들기 전에 config list들이 같은 길이인지 확인합니다.\n",
    "    \n",
    "    input_layer = keras.layers.Input(shape=input_shape)  # input layer를 만들어둡니다.\n",
    "    output = input_layer\n",
    "    \n",
    "    ### Conv1\n",
    "    output = keras.layers.Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size = (7,7),\n",
    "        strides = 2,\n",
    "        padding = 'valid')(output)\n",
    "    output = keras.layers.BatchNormalization()(output)\n",
    "    output = keras.layers.Activation(\"relu\")(output)\n",
    "    output = keras.layers.MaxPooling2D(padding=\"same\")(output)\n",
    "    \n",
    "    # config list들의 길이만큼 반복해서 블록을 생성합니다.\n",
    "    if not is_50:\n",
    "        build_resnet_block = build_resnet34_block\n",
    "    else: \n",
    "        build_resnet_block = build_resnet50_block\n",
    "        \n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        output = build_resnet_block(\n",
    "            output,\n",
    "            num_cnn=num_cnn, \n",
    "            channel=channel,\n",
    "            block_num=i, \n",
    "            is_plain=is_plain\n",
    "        )\n",
    "    \n",
    "    output = keras.layers.AveragePooling2D(padding=\"same\")(output)\n",
    "    output = keras.layers.Flatten(name='flatten')(output)\n",
    "    output = keras.layers.Dense(512, activation='relu', name='fc1000')(output)\n",
    "    output = keras.layers.Dense(num_classes, activation='softmax', name='predictions')(output)\n",
    "    \n",
    "    model = keras.Model(\n",
    "        inputs=input_layer, \n",
    "        outputs=output\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe66c512",
   "metadata": {},
   "source": [
    "### 2) ResNet-34, ResNet-50 Complete Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "28a3f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34_model = build_resnet(input_shape=(224,224,3), is_50=False, is_plain=False)\n",
    "plain34_model = build_resnet(input_shape=(224,224,3), is_50=False, is_plain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aaa1ce40",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_23 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 109, 109, 64) 9472        input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 109, 109, 64) 256         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 109, 109, 64) 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 55, 55, 64)   0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block0_1_conv0 (Conv2D)         (None, 55, 55, 64)   36928       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block0_1_batch_normal0 (BatchNo (None, 55, 55, 64)   256         block0_1_conv0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block0_1_activation0 (Activatio (None, 55, 55, 64)   0           block0_1_batch_normal0[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block0_2_conv0 (Conv2D)         (None, 55, 55, 64)   36928       block0_1_activation0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block0_2_batch_normal0 (BatchNo (None, 55, 55, 64)   256         block0_2_conv0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_136 (Add)                   (None, 55, 55, 64)   0           block0_2_batch_normal0[0][0]     \n",
      "                                                                 max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block0_2_activation0 (Activatio (None, 55, 55, 64)   0           add_136[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block0_1_conv1 (Conv2D)         (None, 55, 55, 64)   36928       block0_2_activation0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block0_1_batch_normal1 (BatchNo (None, 55, 55, 64)   256         block0_1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block0_1_activation1 (Activatio (None, 55, 55, 64)   0           block0_1_batch_normal1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block0_2_conv1 (Conv2D)         (None, 55, 55, 64)   36928       block0_1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block0_2_batch_normal1 (BatchNo (None, 55, 55, 64)   256         block0_2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_137 (Add)                   (None, 55, 55, 64)   0           block0_2_batch_normal1[0][0]     \n",
      "                                                                 block0_2_activation0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block0_2_activation1 (Activatio (None, 55, 55, 64)   0           add_137[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block0_1_conv2 (Conv2D)         (None, 55, 55, 64)   36928       block0_2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block0_1_batch_normal2 (BatchNo (None, 55, 55, 64)   256         block0_1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block0_1_activation2 (Activatio (None, 55, 55, 64)   0           block0_1_batch_normal2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block0_2_conv2 (Conv2D)         (None, 55, 55, 64)   36928       block0_1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block0_2_batch_normal2 (BatchNo (None, 55, 55, 64)   256         block0_2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_138 (Add)                   (None, 55, 55, 64)   0           block0_2_batch_normal2[0][0]     \n",
      "                                                                 block0_2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block0_2_activation2 (Activatio (None, 55, 55, 64)   0           add_138[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_1_conv0 (Conv2D)         (None, 55, 55, 128)  73856       block0_2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1_1_batch_normal0 (BatchNo (None, 55, 55, 128)  512         block1_1_conv0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1_1_activation0 (Activatio (None, 55, 55, 128)  0           block1_1_batch_normal0[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block1_2_conv0 (Conv2D)         (None, 55, 55, 128)  147584      block1_1_activation0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1_2_batch_normal0 (BatchNo (None, 55, 55, 128)  512         block1_2_conv0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 55, 55, 128)  8320        block0_2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_139 (Add)                   (None, 55, 55, 128)  0           block1_2_batch_normal0[0][0]     \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block1_2_activation0 (Activatio (None, 55, 55, 128)  0           add_139[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_1_conv1 (Conv2D)         (None, 55, 55, 128)  147584      block1_2_activation0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1_1_batch_normal1 (BatchNo (None, 55, 55, 128)  512         block1_1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1_1_activation1 (Activatio (None, 55, 55, 128)  0           block1_1_batch_normal1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block1_2_conv1 (Conv2D)         (None, 55, 55, 128)  147584      block1_1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1_2_batch_normal1 (BatchNo (None, 55, 55, 128)  512         block1_2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_140 (Add)                   (None, 55, 55, 128)  0           block1_2_batch_normal1[0][0]     \n",
      "                                                                 block1_2_activation0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1_2_activation1 (Activatio (None, 55, 55, 128)  0           add_140[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_1_conv2 (Conv2D)         (None, 55, 55, 128)  147584      block1_2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1_1_batch_normal2 (BatchNo (None, 55, 55, 128)  512         block1_1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1_1_activation2 (Activatio (None, 55, 55, 128)  0           block1_1_batch_normal2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block1_2_conv2 (Conv2D)         (None, 55, 55, 128)  147584      block1_1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1_2_batch_normal2 (BatchNo (None, 55, 55, 128)  512         block1_2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_141 (Add)                   (None, 55, 55, 128)  0           block1_2_batch_normal2[0][0]     \n",
      "                                                                 block1_2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1_2_activation2 (Activatio (None, 55, 55, 128)  0           add_141[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_1_conv3 (Conv2D)         (None, 55, 55, 128)  147584      block1_2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1_1_batch_normal3 (BatchNo (None, 55, 55, 128)  512         block1_1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1_1_activation3 (Activatio (None, 55, 55, 128)  0           block1_1_batch_normal3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block1_2_conv3 (Conv2D)         (None, 55, 55, 128)  147584      block1_1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1_2_batch_normal3 (BatchNo (None, 55, 55, 128)  512         block1_2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_142 (Add)                   (None, 55, 55, 128)  0           block1_2_batch_normal3[0][0]     \n",
      "                                                                 block1_2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1_2_activation3 (Activatio (None, 55, 55, 128)  0           add_142[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block2_1_conv0 (Conv2D)         (None, 55, 55, 256)  295168      block1_2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2_1_batch_normal0 (BatchNo (None, 55, 55, 256)  1024        block2_1_conv0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2_1_activation0 (Activatio (None, 55, 55, 256)  0           block2_1_batch_normal0[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block2_2_conv0 (Conv2D)         (None, 55, 55, 256)  590080      block2_1_activation0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2_2_batch_normal0 (BatchNo (None, 55, 55, 256)  1024        block2_2_conv0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 55, 55, 256)  33024       block1_2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_143 (Add)                   (None, 55, 55, 256)  0           block2_2_batch_normal0[0][0]     \n",
      "                                                                 conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block2_2_activation0 (Activatio (None, 55, 55, 256)  0           add_143[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block2_1_conv1 (Conv2D)         (None, 55, 55, 256)  590080      block2_2_activation0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2_1_batch_normal1 (BatchNo (None, 55, 55, 256)  1024        block2_1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2_1_activation1 (Activatio (None, 55, 55, 256)  0           block2_1_batch_normal1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block2_2_conv1 (Conv2D)         (None, 55, 55, 256)  590080      block2_1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2_2_batch_normal1 (BatchNo (None, 55, 55, 256)  1024        block2_2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_144 (Add)                   (None, 55, 55, 256)  0           block2_2_batch_normal1[0][0]     \n",
      "                                                                 block2_2_activation0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2_2_activation1 (Activatio (None, 55, 55, 256)  0           add_144[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block2_1_conv2 (Conv2D)         (None, 55, 55, 256)  590080      block2_2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2_1_batch_normal2 (BatchNo (None, 55, 55, 256)  1024        block2_1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2_1_activation2 (Activatio (None, 55, 55, 256)  0           block2_1_batch_normal2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block2_2_conv2 (Conv2D)         (None, 55, 55, 256)  590080      block2_1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2_2_batch_normal2 (BatchNo (None, 55, 55, 256)  1024        block2_2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_145 (Add)                   (None, 55, 55, 256)  0           block2_2_batch_normal2[0][0]     \n",
      "                                                                 block2_2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2_2_activation2 (Activatio (None, 55, 55, 256)  0           add_145[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block2_1_conv3 (Conv2D)         (None, 55, 55, 256)  590080      block2_2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2_1_batch_normal3 (BatchNo (None, 55, 55, 256)  1024        block2_1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2_1_activation3 (Activatio (None, 55, 55, 256)  0           block2_1_batch_normal3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block2_2_conv3 (Conv2D)         (None, 55, 55, 256)  590080      block2_1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2_2_batch_normal3 (BatchNo (None, 55, 55, 256)  1024        block2_2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_146 (Add)                   (None, 55, 55, 256)  0           block2_2_batch_normal3[0][0]     \n",
      "                                                                 block2_2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2_2_activation3 (Activatio (None, 55, 55, 256)  0           add_146[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block2_1_conv4 (Conv2D)         (None, 55, 55, 256)  590080      block2_2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2_1_batch_normal4 (BatchNo (None, 55, 55, 256)  1024        block2_1_conv4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2_1_activation4 (Activatio (None, 55, 55, 256)  0           block2_1_batch_normal4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block2_2_conv4 (Conv2D)         (None, 55, 55, 256)  590080      block2_1_activation4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2_2_batch_normal4 (BatchNo (None, 55, 55, 256)  1024        block2_2_conv4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_147 (Add)                   (None, 55, 55, 256)  0           block2_2_batch_normal4[0][0]     \n",
      "                                                                 block2_2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2_2_activation4 (Activatio (None, 55, 55, 256)  0           add_147[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block2_1_conv5 (Conv2D)         (None, 55, 55, 256)  590080      block2_2_activation4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2_1_batch_normal5 (BatchNo (None, 55, 55, 256)  1024        block2_1_conv5[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2_1_activation5 (Activatio (None, 55, 55, 256)  0           block2_1_batch_normal5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block2_2_conv5 (Conv2D)         (None, 55, 55, 256)  590080      block2_1_activation5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2_2_batch_normal5 (BatchNo (None, 55, 55, 256)  1024        block2_2_conv5[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_148 (Add)                   (None, 55, 55, 256)  0           block2_2_batch_normal5[0][0]     \n",
      "                                                                 block2_2_activation4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2_2_activation5 (Activatio (None, 55, 55, 256)  0           add_148[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block3_1_conv0 (Conv2D)         (None, 55, 55, 512)  1180160     block2_2_activation5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3_1_batch_normal0 (BatchNo (None, 55, 55, 512)  2048        block3_1_conv0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3_1_activation0 (Activatio (None, 55, 55, 512)  0           block3_1_batch_normal0[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_2_conv0 (Conv2D)         (None, 55, 55, 512)  2359808     block3_1_activation0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3_2_batch_normal0 (BatchNo (None, 55, 55, 512)  2048        block3_2_conv0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 55, 55, 512)  131584      block2_2_activation5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_149 (Add)                   (None, 55, 55, 512)  0           block3_2_batch_normal0[0][0]     \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block3_2_activation0 (Activatio (None, 55, 55, 512)  0           add_149[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block3_1_conv1 (Conv2D)         (None, 55, 55, 512)  2359808     block3_2_activation0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3_1_batch_normal1 (BatchNo (None, 55, 55, 512)  2048        block3_1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3_1_activation1 (Activatio (None, 55, 55, 512)  0           block3_1_batch_normal1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_2_conv1 (Conv2D)         (None, 55, 55, 512)  2359808     block3_1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3_2_batch_normal1 (BatchNo (None, 55, 55, 512)  2048        block3_2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_150 (Add)                   (None, 55, 55, 512)  0           block3_2_batch_normal1[0][0]     \n",
      "                                                                 block3_2_activation0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3_2_activation1 (Activatio (None, 55, 55, 512)  0           add_150[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block3_1_conv2 (Conv2D)         (None, 55, 55, 512)  2359808     block3_2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3_1_batch_normal2 (BatchNo (None, 55, 55, 512)  2048        block3_1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3_1_activation2 (Activatio (None, 55, 55, 512)  0           block3_1_batch_normal2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_2_conv2 (Conv2D)         (None, 55, 55, 512)  2359808     block3_1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3_2_batch_normal2 (BatchNo (None, 55, 55, 512)  2048        block3_2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_151 (Add)                   (None, 55, 55, 512)  0           block3_2_batch_normal2[0][0]     \n",
      "                                                                 block3_2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3_2_activation2 (Activatio (None, 55, 55, 512)  0           add_151[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 28, 28, 512)  0           block3_2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 401408)       0           average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fc1000 (Dense)                  (None, 512)          205521408   flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            1026        fc1000[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 226,829,058\n",
      "Trainable params: 226,813,826\n",
      "Non-trainable params: 15,232\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet34_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb5f194d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "failed to allocate memory [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1807/2798207795.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresnet50_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_resnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_50\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_plain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplain50_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_resnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_50\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_plain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1807/1573832009.py\u001b[0m in \u001b[0;36mbuild_resnet\u001b[0;34m(input_shape, num_cnn_list, channel_list, num_classes, is_50, is_plain)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAveragePooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'flatten'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fc1000'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'predictions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    977\u001b[0m                                                 input_list)\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1112\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1113\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1115\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    884\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2657\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                        'should be defined. Found `None`.')\n\u001b[1;32m   1177\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlast_dim\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m     self.kernel = self.add_weight(\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;34m'kernel'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0mcaching_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m     variable = self._add_variable_with_custom_getter(\n\u001b[0m\u001b[1;32m    648\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0;31m# \"best effort\" to set the initializer with the highest restore UID.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_initializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m     new_variable = getter(\n\u001b[0m\u001b[1;32m    814\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    115\u001b[0m   \u001b[0;31m# However, this breaks legacy (Estimator) checkpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m   \u001b[0;31m# because it changes variable names. Remove this when V1 is fully deprecated.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m   return tf.compat.v1.Variable(\n\u001b[0m\u001b[1;32m    118\u001b[0m       \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maggregation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m       \u001b[0maggregation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariableAggregation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNONE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     return previous_getter(\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m                         shape=None):\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2610\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2611\u001b[0m     \u001b[0mdistribute_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"distribute_strategy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2612\u001b[0;31m     return resource_variable_ops.ResourceVariable(\n\u001b[0m\u001b[1;32m   2613\u001b[0m         \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2614\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1600\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_from_proto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimport_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1602\u001b[0;31m       self._init_from_args(\n\u001b[0m\u001b[1;32m   1603\u001b[0m           \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1738\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1739\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1740\u001b[0;31m               \u001b[0minitial_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1741\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointInitialValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_initialize_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/initializers/initializers_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/initializers/initializers_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m    970\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m       \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m     return op(\n\u001b[0m\u001b[1;32m    973\u001b[0m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    313\u001b[0m           \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmaxval\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m     \u001b[0;31m# TODO(b/132092188): C++ shape inference inside functional ops does not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;31m# cross FuncGraph boundaries since that information is only available in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   3941\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3942\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3943\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    453\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: failed to allocate memory [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "resnet50_model = build_resnet(input_shape=(224,224,3), is_50=True, is_plain=False)\n",
    "plain50_model = build_resnet(input_shape=(224,224,3), is_50=True, is_plain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50562f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5579e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f6d73d",
   "metadata": {},
   "source": [
    "### 3) 일반 네트워크(plain network) 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8038006",
   "metadata": {},
   "outputs": [],
   "source": [
    "plain34_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fba72d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plain50_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b22e40d",
   "metadata": {},
   "source": [
    "### 4) ResNet-50 vs Plain-50 또는 ResNet-34 vs Plain-34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5f5fb4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "#tfds.disable_progress_bar()   # 이 주석을 풀면 데이터셋 다운로드과정의 프로그레스바가 나타나지 않습니다.\n",
    "setattr(tfds.image_classification.cats_vs_dogs, '_URL',\"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\")\n",
    "\n",
    "datasets, info = tfds.load('cats_vs_dogs', \n",
    "                     split=['train[:80%]', 'train[80%:]'], \n",
    "                     with_info=True, \n",
    "                     as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3fc8c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "335c5fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, label):\n",
    "    image = tf.image.resize(image, [224,224])  # 이미지 크기 조정\n",
    "    image = image / 255.0  # 정규화\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ffba0f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 적용\n",
    "train_dataset = train_dataset.map(preprocess_image).batch(16).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.map(preprocess_image).batch(16).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "506cd290",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (64, 224, 224, 3)\n",
      "Labels shape: (64,)\n"
     ]
    }
   ],
   "source": [
    "# 이미지와 라벨 구분\n",
    "for images, labels in train_dataset.take(1):  # 첫 배치 가져오기\n",
    "    # 이미지와 라벨 확인\n",
    "    print(\"Images shape:\", images.shape)  # 이미지 텐서의 shape\n",
    "    print(\"Labels shape:\", labels.shape)  # 라벨 텐서의 shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4b01ae55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## 모델 complie\n",
    "resnet34_model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.01, clipnorm=1.),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "plain34_model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.01, clipnorm=1.),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "resnet50_model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.01, clipnorm=1.),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "plain50_model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.01, clipnorm=1.),\n",
    "    metrics=['accuracy'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "be25a33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "dbdf72da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[64,512,56,56] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_26/block3_2_conv0/Conv2D (defined at tmp/ipykernel_37/2386665842.py:1) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_209252]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37/2386665842.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history_resnet34 = resnet34_model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     steps_per_epoch=int(train_dataset.splits['train'].num_examples/BATCH_SIZE),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     validation_steps=int(train_dataset.splits['test'].num_examples/BATCH_SIZE),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[64,512,56,56] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_26/block3_2_conv0/Conv2D (defined at tmp/ipykernel_37/2386665842.py:1) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_209252]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "history_resnet34 = resnet34_model.fit(\n",
    "    train_dataset,\n",
    "#     steps_per_epoch=int(train_dataset.splits['train'].num_examples/BATCH_SIZE),\n",
    "#     validation_steps=int(train_dataset.splits['test'].num_examples/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=test_dataset,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c474912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_plain34 = plain34_model.fit(\n",
    "    train_dataset,\n",
    "#     steps_per_epoch=int(train_dataset.splits['train'].num_examples/BATCH_SIZE),\n",
    "#     validation_steps=int(train_dataset.splits['test'].num_examples/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=test_dataset,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff332e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history_resnet34.history['loss'], 'r')\n",
    "plt.plot(history_plain34.history['loss'], 'b')\n",
    "plt.title('Model training loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['vgg_16', 'vgg_19'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
